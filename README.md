# Домашнее задание № 1

# Цель проекта
Научиться использовать DVC и MLFlow для создания полностью воспроизводимого жизненного цикла обучения модели машинного обучения. Научиться пользоваться git, DVC, MLflow на примере реальной задачи классификации.

# Краткое описание пайплайна
Пайплайн состоит из двух этапов:
1. Загрузка сырых данных и разбиение их на два датасета - train и test. Отделение признаков от целевых переменных.
2. Обучение модели а так же валидациия на тренировочных и тестовых данных. Подсчёт метрики accuracy. Сохранение модели в загружаемый файл `model.pkl`.

# Установка

## UV
Решение использует современный пакетный менеджер python `uv`. Для дальнейшей работы необходима установка только этой системной зависимости. Для его установки необходимо выполнить следующие команды:
* Windows: `powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"`
* Linux / MacOS: `curl -LsSf https://astral.sh/uv/install.sh | sh`

## MLFlow
При исполнении пайплайна происходил логирование обучаемой модели в MLFlow. Для локального запуска (**после установки зависимостей python и активации виртуального окружения**) необходимо выполнить команду:
```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```
UI сервера MLFlow будет доступен по адресу `127.0.0.1:5000`

# Запуск пайплайна
Перед началом работы с пайплайном необходимо склонировать репозиторий:
```bash
git clone git@github.com:FrankensteinPillow/mlops_hw1_ilia_zubov.git
```
Перейдём в директорию с решением:
```bash
cd mlops_hw1_ilia_zubov
```
Далее установим необходимые зависимости (список зависимостей указан в файле `pyproject.toml`) а так же активируем виртуальное окружение для удобства:
```bash
uv sync
source .venv/bin/activate
```
Загрузим данные, необходимые для обучения модели. В качестве учебного решения скачаем данные из Kaggle и распакуем архив:
```bash
curl -L -o iris.zip https://www.kaggle.com/api/v1/datasets/download/uciml/iris && \
unzip iris.zip -d iris && \
mv iris/Iris.csv ./data/raw/iris.csv && \
rm ./iris.zip && \
rm -rf ./iris
```
Я не смог найти бесплатного решения для хостинга своего датасета для публичного доступа, поэтому использовал решение выше. Однако на продакшене можно воспользоваться gcloud bucket-ами от Google или s3 хранилищем от AWS и настроить интеграциию например таким образом:
```bash
dvc remote add -d s3-public s3://my-dvc-bucket/data
```
В моём `.dvc/config` указана заглушка для такого публичного s3 хранилища. Далее можно выполнить команду указанную ниже и данные успешно сохраняться в нужную директорию
```bash
dvc pull
```
После того как данные были доабвлены в директорию `./data/raw` запустим пайплайн обучения:
```bash
dvc repro
```
Проверим получившиеся метрики:
```bash
dvc metrics show
```
